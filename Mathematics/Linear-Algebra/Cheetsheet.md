# Cheetsheet

Created: 2018-05-26 12:33:00 +0500

Modified: 2020-11-22 20:34:01 +0500

---

<https://www.freecodecamp.org/news/linear-algebra-full-course/>
![Linear algebra explained in four page: Excerpt from the No BULLSHIT GUIDE TO LINEAR ALGEBRA by Ivan Savo Abstract---This document Will review the fundamental ideas Of linear algebra. We will learn about matrices, matrix operations, linear transformations and discuss both the theoretical and computational aspects Of linear algebra. The tools of linear algebra open the gateway to the study of more advanced mathematics. A lot Of knowledge buzz awaits you if you choose to follow the path Of understanding, instead Of trying to memorize a bunch Of formulas. I. INTRODUCTION Linear algebra is the math of vectors and matrices. Let n be a positive integer and let R denote the set of real numbers, then is the set of all n-tuples of real numbers. A vector e R n is an n-tuple of real numbers. The notation ' 'G S' is read "element of S." For example, consider a vector that has three components: F = e (R, R, R) æR3. A matrix A e is a rectangular array of real numbers with m rows and n columns. For example, a 3 x 2 matrix looks like this: B. Matrix operations We denote by A the matrix as a wh The mathematical operations defined fo addition (denoted + ) subtraction (the inverse of addition matrix product. The product of ma is another matrix C € IR m xe an avg 1 C = AB al'2 b12 a22 b21 b22 a32 given all bl (131 bl all 012 (121 022 032 IR IR R3x2. The purpose of this document is to introduce you to the mathematical operations that we can perform on vectors and matrices and to give you a feel of the power of linear algebra. Many problems in science, business, and technology can be described in terms of vectors and matrices so it is important that you understand how to work with these. Prerequisites The only prerequisite for this tutorial is a basic understanding of high school math conceptsl like numbers, variables, equations, and the fundamental arithmetic operations on real numbers: addition (denoted -F), subtraction (denoted ---), multiplication (denoted implicitly), and division (fractions). You should also be familiar with functions that take real numbers as inputs and give real numbers as outputs, f : R ---4 R. Recall that, by definition, the inverse function f 1 undoes the effect of f. If you are given f (x) and you want to find you can use the inverse function as follows: (f(x)) x. For example, the function f (x) = In(x) has the inverse ex, and the inverse of g(x) = is = x2. Il. DEFINITIONS A. Vector operations We now define the math operations for vectors. The operations we can (VI, v2, v3) are: addition, perform on vectors = 111, t12, ug) and V = subtraction, scaling, norm (length), dot product, and cross product: d -F F = 011 u'2 + + v.3) matrix inverse (denoted A matrix transpose (denoted T): 02 03 '31 (32 '33 matrix trace: Tr(A) Etn=l aii determinant (denoted det(A) or IA Note that the matrix product is not a co C. Matrix-vector product The matrix-vector product is an imp matrix product. The product of a 3 x vector results in a 3 x I vector j giu all an all (121 am all, (a31 , There are tw02 fundamentally different matrix-vector product. In the column pic matrix A by the vector produces a lin ](media/Cheetsheet-image1.png)

![Instead of writing = T A (i) for the linear transformation TA applied to the vector i, we simply write j AE. Applying the linear transformation TA to the vector .F corresponds to the product of the matrix A and the column vector E. We say TA is represented by the matrix A. You can think of linear transformations as "vector functions" and describe their properties in analogy with the regular functions you are familiar with: function f : R -9 R input x G R output go f function inverse zeros of f range of f linear transformation TA : R n ---+ R m input G output T A (i) = AE e matrix inverse A N (A) E- null space of A C(A) column space of A range of T A Note that the combined effect of applying the transformation TA followed by TB on the input vector is equivalent to the matrix product 13 AE. E. Fundamental vector spaces A vector space consists of a set of vectors and all linear combinations of these vectors. For example the vector space S = span{F1, F2} consists of all vectors of the form = aF1 + '3132, where a and '3 are real numbers. We now define three fundamental vector spaces associated with a matrix A. The column space of a matrix A is the set of vectors that can be produced as linear combinations of the columns of the matrix A: C(A) -E {j e IR m I for some IR n } . The column space is the range of the linear transformation TA (the set of possible outputs). You can convince yourself of this fact by reviewing the definition of the matrix-vector product in the column picture (C). The vector AE contains times the I st column of A, times the 2nd column of A, etc. Varying over all possible inputs F, we obtain all possible linear combinations of the columns of A, hence the name "column space." The null space MA) of a matrix A € IR m x n consists of all the vectors that the matrix A sends to the zero vector. The vectors in the null space are orthogonal to all the rows of the matrix. We can see this from the row picture (R): the output vectors is (j if and only if the input vector is orthogonal to all the rows of A. The row space of a matrix A, denoted R(A), is the set of linear combinations of the rows of A. The row space R(A) is the orthogonal complement of the null space N This means that for all vectors e R(A) and all vectors e M (A), we have • ti.; = O. Together, the null space and the row space form the domain of the transformation T A, IR n = M (A) R(Ä), where stands for orthogonal direct sum. E Matrix inverse Ill. COMPUTATIONAL I Okay, I hear what you are saying "Dud see some calculations." In this section w algorithms of linear algebra called Gaus A. Solving systems of equations Suppose we're asked to solve the foll 3X1 + 9.1'2 Without a knowledge of linear algebra, tion, or subtraction to find the values of Gauss---Jordan elimination is a system of equations based the following tow o/ a) Adding a multiple of one row to al {3) Swapping two rows 7) Multiplying a row by a constant These row operations allow us to simpli changing their solution. To illustrate the Gauss---Jordan elimina sequence of row operations required to s described above. We start by constructin The first column in the augmented matri: the variable Xl, the second column con and the third column contains the const The Gauss-Jordan elimination procedl the first phase, we proceed left-to-right one in the leftmost column (called a pil that row from all rows below it to get ze the second phase, we start with the righ all the numbers above it in the same co I) 2) 3) The first step is to use the pivot Il variable in the second row. We the first row from the second row, Next, we create a pivot in the sec We now start the backward phase from the first row. We do this by row from the first row RI e--- RI • The matrix is now in reduced ](media/Cheetsheet-image2.png)

![IV. COMPUTING THE INVERSE OF A MATRIX In this section we'll look at several different approaches for computing the inverse of a matrix. The matrix inverse is unique so no matter which method we use to find the inverse, we'll always obtain the same answer. A. Using row operations One approach for computing the inverse is to use the Gauss---Jordan elimination procedure. Start by creating an array containing the entries of the matrix A on the left side and the identity matrix on the right side: 121 0 39() 1 Now we perform the Gauss-Jordan elimination procedure on this array. l) The first row operation is to subtract three times the first row from the second row: 112 e--- 112 --- 3111. We obtain: • åR2 2) The second row operation is divide the second row by 3. 1 1 ---1 3) The third row operation is RI e--- RI --- 2112 2 3 1 ---1 3 The array is now in reduced row echelon form (RREF). The inverse matrix appears on the right side of the array. Observe that the sequence of row operations we used to solve the specific system of equations in b in the previous section are the same as the row operations we used in this section to find the inverse matrix. Indeed, in both cases the combined effect of the three row operations is to "undo" the effects of A. The right side of the 2 x 4 array is simply a convenient way to record this sequence of operations and thus obtain A I B. Using elementary matrices Every row operation we perform on a matrix is equivalent to a left- multiplication by an elementary matrix. There are three types of elementary matrices in correspondence with the three types of row operations: C. Using a computer The last (and most practical) approach is to use a computer algebra system lik A = Matrix( [[1,2), [3,911 >>> A. inv() [3, -2/3) 1/31 [-1, You can use sympy to "check" your V. OTHER We'll now discuss a number of other A. Basis Intuitively, a basis is any set of vect01 system for a vector space. You are certail for the xy-plane that is made up of tw the y-axis. A vector can be described respect to these axes, or equivalently and j (O, I) are unit vectors that respectively. However, other coordinate Definition (Basis). A basis for a n-dim of n linearly independent vectors that Any set of two linearly independent vec for R 2. We can write any vector F e R basis vectors F = l,'lél + V2é2. Note the same vector corresponds to ing on the basis used: = (vr, vy) in F = (VI, v2) in the basis Be {él, é2 in mind the basis with respect to whict necessary specify the basis as a subscril Converting a coordinate vector from performed as a multiplication by a chan 'F 'F : RI RI + mR2 1 o o 1 m o m 1 1 o o 1 Let's revisit the row operations we used to find in the above section representing each row operation as an elementary matrix multiplication. l) The first row operation R2 --- 3R1 corresponds to a multipli- cation by the elementary matrix El : 1 01 [1 21 [1 21 Note the change of basis matrix is actua vector F remains unchanged---it is simpl coordinate system. The change of basis is accomplished using the inverse B. Matrix representations of linear tran Bases play an important role in the r' tions T: R n ---4 IR"'. To fully describe tl linear transformation T, it is sufficient vectors of the standard basis for the inpu T: R 2 ---+ 122, the matrix representation ](media/Cheetsheet-image3.png)

![C. Dimension and bases for vector spaces The dimension of a vector space is defined as the number of vectors in a bæsis for that vector space. Consider the following vector space S span{(l, O, O), (O, 1, O), (1, 1, O)}. Seeing that the space is described by three vectors, we might think that S is 3-dimensional. This is not the case, however, since the three vectors are not linearly independent so they don't form a basis for S. Two vectors are sufficient to describe any vector in S; we can write S = span{(1,O, O), (O, 1, O)}, and we see these two vectors are linearly independent so they form a basis and dim(S) = 2. There is a general procedure for finding a basis for a vector space. Suppose you are given a description of a vector space in terms of m vectors V = span{FI, • , and you are asked to find a basis for V and the dimension of V. To find a basis for V, you must find a set of linearly independent vectors that span V. We can use the Gauss---Jordan elimination procedure to accomplish this task Write the vectors as the rows of a matrix M. The vector space V corresponds to the row space of the matrix M. Next, use row operations to find the reduced row echelon form (RREF) of the matrix M. Since row operations do not change the row space of the matrix, the row space of reduced row echelon form of the matrix M is the same as the row space of the original set of vectors. The nonzero rows in the RREF of the matrix form a basis for vector space V and the numbers of nonzero rows is the dimension of V. D. Row space, columns space, and rank of a matrix Recall the fundamental vector spaces for matrices that we defined in Section Il-E: the column space C(A), the null space N (A), and the row space R(A). A standard linear algebra exam question is to give you a certain matrix A and ask you to find the dimension and a basis for each of its fundamental spaces. In the previous section we described a procedure based on Gauss---Jordan elimination which can be used "distill" a set of linearly independent vectors which form a basis for the row space R(A). We will now illustrate this procedure with an example, and also show how to use the RREF of the matrix A to find bases for C(A) and N (A). Consider the following matrix and its reduced row echelon form: 1 €3 3.3 267 c, 3 9 9 10 1 30 0 The reduced row echelon form of the matrix A contains three pivots. The locations of the pivots will play an important role in the following steps. The vectors {(1, 3, O, O), (O, O, 1, O), (O, O, O, 1)} form a basis for R(A). To find a basis for the column space C(A) of the matrix A we need to find which of the columns of A are linearly independent. We can do this by identifying the columns which contain the leading ones in rref(A). The corresponding columns in the original matrix form a basis for the column space of A. Looking at rref(A) we see the first, third, and fourth columns of the matrix are linearly independent so the vectors {(1, 2, 3) T, (3, 7, 9) T, (3, 6, 10) T} form a basis for C(A). E. Invertible matrix theorem There is an important distinction betw those that are not as formalized by the Theorem. For an n x n matrix A, theft l) A is invertible 2) The RREF of A is the n x n iden 3) The rank of the matrix is n 4) The row space of A is R n 5) The column space of A is IR n 6) A doesn't have a null space (only 7) The determinant of A is nonzero For a given matrix A, the above statem An invertible matrix A corresponds tc maps the n-dimensional input vector spa vector space R n such that there exists a can faithfully undo the effects of T A. On the other hand, an n X n matrix input vector space R n to a subspace CO space. Once TB sends a vector e that can undo this operation. E Determinants The determinant of a matrix, denoted combine the entries of a matrix that serv or not. The determinant formulas for 2 all al'2 = --- 012021, (121 a22 all (113 022 a23 021 (122 a23 = all 032 (133 am 0.32 a33 If the IAI = O then A is not invertible. G. Eigenvalues and eigenvectors The set of eigenvectors of a matrix i: which the action of the matrix is desc a matrix is multiplied by one of its eigenvector multiplied by a constant Aé an eigenvalue of A. To find the eigenvalues of a matrix we VA, insert the identity I, and This equation will have a solution whene , denoted {Al, , Of r X n IA --- All. The polynomial --- eigenvalue are the vectors in the null Certain matrices can be written entir and their eigenvalues. Consider the mal the matrix A on the diagonal, and ](media/Cheetsheet-image4.png)
