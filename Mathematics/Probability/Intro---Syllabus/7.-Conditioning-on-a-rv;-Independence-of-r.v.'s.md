# 7. Conditioning on a rv; Independence of r.v.'s

Created: 2018-06-13 02:20:27 +0500

Modified: 2018-06-13 22:35:18 +0500

---

![LECTURE 7: Conditioning on a random variable; Conditional PMFs Conditional expectations --- Total expectation theorem Independence of r.v.'s Expectation properties --- Variance properties The variance of the binomial Independ ](media/Intro---Syllabus_7.-Conditioning-on-a-rv;-Independence-of-r.v.'s-image1.png){width="12.09375in" height="6.84375in"}

![Conditional PMFs pxlA(x I A) --- pxlY(x I y) = pxly(x I y) = P (X = x I Y = y) z defined for y such that py(y) > O (L) 5/20 (112) = o 4 3 1/20 2/20 2/20 4/20 2/20 1/20 py(y) 2/20 ](media/Intro---Syllabus_7.-Conditioning-on-a-rv;-Independence-of-r.v.'s-image2.png){width="12.09375in" height="6.84375in"}

![Conditional PMFs involving more than two r.v.'s Self-explanatory notation L ( Y = 72 2 = a-) I z) J? 22) Multiplication rule pan B n c) P(A) I A) I An B) ](media/Intro---Syllabus_7.-Conditioning-on-a-rv;-Independence-of-r.v.'s-image3.png){width="12.09375in" height="6.84375in"}

![Conditional expectation Expected value rule = EXPXIA(X) ¯ E g(x) pxlA(x) ](media/Intro---Syllabus_7.-Conditioning-on-a-rv;-Independence-of-r.v.'s-image4.png){width="12.09375in" height="6.84375in"}

![Total probability and expectation theorems Al, ,An: partition of Q px(x) = P(AI) (x) + • • • + P(An) pxIAn(x) px(x) = pxIY(x I y) • E[X] = P(AI) I Al] + + P(An) I An] ](media/Intro---Syllabus_7.-Conditioning-on-a-rv;-Independence-of-r.v.'s-image5.png){width="12.09375in" height="6.84375in"}

![Independence of two events: n B) = P(A) • PCB) of a r.v. and an event: P(X = x and A) P(X = x) P(A) ort 'z of two r.v. 's: = x and Y = y) = x) • = y y) = px(x) Py(y), for all x, y ](media/Intro---Syllabus_7.-Conditioning-on-a-rv;-Independence-of-r.v.'s-image6.png){width="12.09375in" height="6.84375in"}

![Example: independence and conditional independence 4 3 2 1/20 2/20 1 2/20 4/20 1/20 1/20 2 2/20 1/20 3/20 3 Independent? NO 2/20 PX (l) : 3/20 1/20 x 4 What if we condition on X < 2 ](media/Intro---Syllabus_7.-Conditioning-on-a-rv;-Independence-of-r.v.'s-image7.png){width="12.09375in" height="6.84375in"}

![Independence and expectations • In general: E[g(X, Y)] Exceptions: E[ax + b] = aE[x] + b E[XY] --- If X, Y are independent: g(X) and h(Y) are also independent: ](media/Intro---Syllabus_7.-Conditioning-on-a-rv;-Independence-of-r.v.'s-image8.png){width="12.09375in" height="6.84375in"}

![Independence and variances Always true: var(aX) = a2var(X) var (x + a) • In general: var(X + Y) # var(X) + var(Y) = var(X) If X, Y are independent: var(X + Y) = var(X) + var(Y) Y 22 = var (x) Examples: ](media/Intro---Syllabus_7.-Conditioning-on-a-rv;-Independence-of-r.v.'s-image9.png){width="12.09375in" height="6.84375in"}

![Variance of the binomial X: binomial with parameters n, p number of successes in n independent trials Xi=l if ith trial is a success; Xi = O otherwise 2 n , VQP(ÄI (indicator variable) . t v (x A(XW) ](media/Intro---Syllabus_7.-Conditioning-on-a-rv;-Independence-of-r.v.'s-image10.png){width="12.09375in" height="6.84375in"}

![The hat problem n people throw their hats in a box and then --- All permutations equally likely Equivalent to picking one hat at a time X: number of people who get their own hat FindEl +0 if i selects own hat 1, O, otherwise. pick one at randon 1 PX(k) ](media/Intro---Syllabus_7.-Conditioning-on-a-rv;-Independence-of-r.v.'s-image11.png){width="12.09375in" height="6.84375in"}

![The variance in the hat problem X: number of people who get their own hat --- Find var(X) if i selects own hat 1, O, otherwise. var(X) = E[x2] - x2 For i # j: E[XtXj] = g [X, & ] = f (X, l) (X) ](media/Intro---Syllabus_7.-Conditioning-on-a-rv;-Independence-of-r.v.'s-image12.png){width="12.09375in" height="6.84375in"}

**Joint PMF**
**Conditional PMF**

**Marginal PMF**

By keeping y fixed
In PMF Notation
Joint PMF factors out as a product of the marginal PMFs of the two random variable
Entry of the joint PMF is equal to the product of the corresponding entries of the marginal PMFs. Therefore the two random variable X and Y are independent in the conditional universe.
