# Generalization and Sampling

Created: 2018-07-02 02:31:51 +0500

Modified: 2021-06-19 14:19:55 +0500

---

## Learn how to

- Assess if your model is overfitting
- Gauge when to stop model training
- Create repeatable training, evaluation, and test datasets
- Establish performance benchmarks

## Loss Metrics

- MSE = Mean Squared Error
- RMSE = Root Mean Squared Error

![image](media/Generalization-and-Sampling-image1.png)

![image](media/Generalization-and-Sampling-image2.png)

![image](media/Generalization-and-Sampling-image3.png)

![image](media/Generalization-and-Sampling-image4.png)

![image](media/Generalization-and-Sampling-image5.png)

![image](media/Generalization-and-Sampling-image6.png)

![image](media/Generalization-and-Sampling-image7.png)

![image](media/Generalization-and-Sampling-image8.png)

![image](media/Generalization-and-Sampling-image9.png)

![image](media/Generalization-and-Sampling-image10.png)

![image](media/Generalization-and-Sampling-image11.png)

![image](media/Generalization-and-Sampling-image12.png)

![image](media/Generalization-and-Sampling-image13.png)

![image](media/Generalization-and-Sampling-image14.png)

![image](media/Generalization-and-Sampling-image15.png)

![image](media/Generalization-and-Sampling-image16.png)

![胆 」 ロ ](media/Generalization-and-Sampling-image17.png)

![image](media/Generalization-and-Sampling-image18.png)

## Summary

- Taking a derivative of our loss services as our guide towards a minima
- We could have more than one minima for complex services
- Loss functions
  - RMSE for regression problems
  - Cross entropy for classification

<https://machinelearningmastery.com/cross-entropy-for-machine-learning>

- Perfectly accurate model with an RMSE of zero, can perform badly against a set of new data that it had not seen before
- Generalization
- Data preparation
  - training
  - evaluation
  - testing
- Overfitting
- underfitting
- ![image](media/Generalization-and-Sampling-image19.png)
